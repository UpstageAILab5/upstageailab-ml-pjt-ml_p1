# docker-compose.yml
# 이 파일은 Airflow와 MLflow를 위한 Docker 컨테이너 구성을 정의합니다.

version: "3.8"  # Docker Compose 파일 형식 버전 지정

services:
  # PostgreSQL 데이터베이스 서비스 설정
  # Airflow의 메타데이터 저장소로 사용됩니다.
  postgres:
    image: postgres:13  # PostgreSQL 13 버전 이미지 사용
    environment:  # 데이터베이스 접속 정보 설정
      POSTGRES_USER: airflow  # 데이터베이스 사용자명
      POSTGRES_PASSWORD: airflow  # 데이터베이스 비밀번호 
      POSTGRES_DB: airflow  # 데이터베이스 이름
    volumes:  # 데이터 영구 저장을 위한 볼륨 마운트
      - postgres_data:/var/lib/postgresql/data
    healthcheck:  # 컨테이너 헬스체크 설정
      test: ["CMD-SHELL", "pg_isready -U airflow"]  # PostgreSQL 서버 상태 확인
      interval: 10s  # 체크 주기
      timeout: 5s  # 타임아웃 시간
      retries: 5  # 재시도 횟수

  # Airflow 초기화 서비스
  # 데이터베이스 초기화 및 관리자 계정 생성을 담당
  airflow-init:
    build:
      context: .  # 현재 디렉토리를 빌드 컨텍스트로 사용
      dockerfile: Dockerfile  # 커스텀 Dockerfile 사용
    image: june-airflow  # 빌드된 이미지의 이름
    depends_on:  # PostgreSQL 서비스 의존성 설정
      - postgres
    environment:  # Airflow 환경 변수 설정
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow  # DB 연결 문자열
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor  # 로컬 실행자 사용
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True  # 새로운 DAG 생성시 일시정지 상태로 시작
      - AIRFLOW__CORE__LOAD_EXAMPLES=False  # 예제 DAG 로드하지 않음
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000  # MLflow 서버 주소
      - PYTHONPATH=/opt/airflow/scripts  # Python 모듈 검색 경로 추가
    volumes:  # 호스트-컨테이너 간 디렉토리 마운트
      - ./dags:/opt/airflow/dags  # DAG 파일 저장 위치
      - ./logs:/opt/airflow/logs  # 로그 파일 저장 위치
      - ./plugins:/opt/airflow/plugins  # 플러그인 저장 위치
      - ./scripts:/opt/airflow/scripts  # 스크립트 파일 저장 위치
      - ./data:/opt/airflow/data  # 데이터 파일 저장 위치
    entrypoint: >  # 초기화 명령어 실행
      bash -c "
        airflow db init &&  # DB 초기화
        airflow users create \  # 관리자 계정 생성
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com ||
        echo 'User already exists.'  # 계정이 이미 존재하는 경우 메시지 출력
      "

  # Airflow 웹 서버 서비스
  # Airflow UI를 제공하는 웹 인터페이스
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    image: june-airflow
    restart: always  # 컨테이너 자동 재시작 설정
    depends_on:  # 서비스 의존성 설정
      - airflow-init
      - postgres
    environment:  # Airflow 환경 변수 설정
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=60  # DAG 디렉토리 스캔 주기(초)
      - AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=10  # 파일 처리 최소 간격(초)
      - PYTHONPATH=/opt/airflow/scripts
    volumes:  # 볼륨 마운트 설정
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
    ports:
      - "8080:8080"  # 웹 UI 포트 매핑
    command: webserver  # 웹 서버 실행 명령어

  # Airflow 스케줄러 서비스
  # DAG 실행을 관리하고 스케줄링하는 서비스
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    image: june-airflow
    restart: always
    depends_on:
      - airflow-webserver
      - postgres
    environment:  # 스케줄러 환경 변수 설정
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=60
      - AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=10
      - PYTHONPATH=/opt/airflow/scripts
    volumes:  # 볼륨 마운트 설정
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./scripts:/opt/airflow/scripts
      - ./data:/opt/airflow/data
    command: scheduler  # 스케줄러 실행 명령어

  # MLflow 서버 서비스
  # 머신러닝 실험 관리 및 모델 추적을 위한 서비스
  mlflow-server:
    build:
      context: .
      dockerfile: Dockerfile.mlflow  # MLflow용 Dockerfile 사용
    container_name: mlflow-server  # 컨테이너 이름 지정
    ports:
      - "5000:5000"  # MLflow UI 포트 매핑
    volumes:
      - "./mlruns:/mlruns"  # MLflow 실험 결과 저장 경로
    environment:
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlruns  # 아티팩트 저장 루트 경로
    depends_on:
      - postgres  # PostgreSQL 의존성 설정

# 도커 볼륨 정의
volumes:
  postgres_data:  # PostgreSQL 데이터 영구 저장을 위한 볼륨
